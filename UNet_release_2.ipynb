{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ed877",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ЗАГРУЗКА ОБУЧАЮЩЕЙ ВЫБОРКИ\n",
    "def input_data():\n",
    "        \n",
    "    #Подготовка данных и выделение признаков\n",
    "    data = torch.zeros((0,1,572,572))\n",
    "\n",
    "    for j in range(2):\n",
    "\n",
    "        i = 1\n",
    "        if (j == 0): name_part = 'yes'; n = 123;          \n",
    "        elif (j == 1): name_part = 'no'; n = 82;\n",
    "\n",
    "        for i in range(1,n):\n",
    "\n",
    "            # Загрузка изображения\n",
    "            s = 'images/brain_tumor_dataset/' + str(name_part) + '/1 (' + str(i) + ').jpg'\n",
    "            img = cv.imread(s,0) \n",
    "\n",
    "            x_new = 572\n",
    "            y_new = 572\n",
    "            dsize = (x_new, y_new)\n",
    "            output = cv.resize(img, dsize, interpolation = cv.INTER_AREA)\n",
    "            output = torch.tensor([[output.T]]).float()\n",
    "            \n",
    "            mean = output.mean()\n",
    "            max_ = output.max()\n",
    "            output_ = (output - mean) / max_\n",
    "            \n",
    "            plt.imshow(output_[0][0].T, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "            data = torch.cat((data, output_))\n",
    "            print(s)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ce133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАГРУЗКА МАСКИ\n",
    "def mask_data():\n",
    "        \n",
    "    #Подготовка данных и выделение признаков\n",
    "    data = torch.zeros((0,3,388,388))\n",
    "    \n",
    "    for j in range(2):\n",
    "\n",
    "        i = 1\n",
    "        if (j == 0): name_part = 'mask'; n = 123;          \n",
    "        elif (j == 1): name_part = 'no'; n = 82;\n",
    "\n",
    "        for i in range(1,n):\n",
    "        \n",
    "            # Загрузка изображения\n",
    "            s = 'images/brain_tumor_dataset/' + str(name_part) + '/1 (' + str(i) + ').jpg'\n",
    "            img = cv.imread(s,1) # ТЕНЗОР 3 РАНГА\n",
    "\n",
    "            # Приведение к одному разрешению\n",
    "            x_new = 388\n",
    "            y_new = 388\n",
    "            dsize = (x_new, y_new)\n",
    "            output = cv.resize(img, dsize, interpolation = cv.INTER_AREA)\n",
    "            output = torch.tensor([output.T]).float()\n",
    "\n",
    "            mean = output.mean()\n",
    "            max_ = output.max()\n",
    "            output_ = (output - mean) / max_\n",
    "\n",
    "            plt.imshow(output_[0].T)\n",
    "            plt.show()\n",
    "\n",
    "            data = torch.cat((data, output_))\n",
    "            print(s)\n",
    "\n",
    "    return data\n",
    "\n",
    "data_mask = mask_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_mask = shuffle(data, data_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size = 3),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size = 3),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea453b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(tensor, target_tensor):\n",
    "    target_size = target_tensor.size()[2]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size\n",
    "    delta = delta // 2\n",
    "    return tensor[:, :, delta:tensor_size - delta, delta:tensor_size - delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()   # При наследовании классов\n",
    "        \n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.down_conv_1 = double_conv(1, 64)\n",
    "        self.down_conv_2 = double_conv(64, 128)\n",
    "        self.down_conv_3 = double_conv(128, 256)\n",
    "        self.down_conv_4 = double_conv(256, 512)\n",
    "        self.down_conv_5 = double_conv(512, 1024)\n",
    "        \n",
    "        self.up_trans_1 = nn.ConvTranspose2d(\n",
    "            in_channels = 1024, \n",
    "            out_channels = 512,\n",
    "            kernel_size = 2, \n",
    "            stride = 2)\n",
    "        self.up_conv_1 = double_conv(1024, 512)\n",
    "        \n",
    "        self.up_trans_2 = nn.ConvTranspose2d(\n",
    "            in_channels = 512, \n",
    "            out_channels = 256,\n",
    "            kernel_size = 2, \n",
    "            stride = 2)\n",
    "        self.up_conv_2 = double_conv(512, 256)\n",
    "        \n",
    "        self.up_trans_3 = nn.ConvTranspose2d(\n",
    "            in_channels = 256, \n",
    "            out_channels = 128,\n",
    "            kernel_size = 2, \n",
    "            stride = 2)\n",
    "        self.up_conv_3 = double_conv(256, 128)\n",
    "        \n",
    "        self.up_trans_4 = nn.ConvTranspose2d(\n",
    "            in_channels = 128, \n",
    "            out_channels = 64,\n",
    "            kernel_size = 2, \n",
    "            stride = 2)\n",
    "        self.up_conv_4 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels = 64,\n",
    "            out_channels = 3,\n",
    "            kernel_size = 1)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        x1 = self.down_conv_1(image)  # ---->\n",
    "        #print(x1.size())\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        x3 = self.down_conv_2(x2) # ---->\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        x5 = self.down_conv_3(x4) # ---->\n",
    "        x6 = self.max_pool_2x2(x5)\n",
    "        x7 = self.down_conv_4(x6) # ---->\n",
    "        x8 = self.max_pool_2x2(x7)\n",
    "        x9 = self.down_conv_5(x8)\n",
    "        #print(x9.size())\n",
    "        \n",
    "        # decoder\n",
    "        x = self.up_trans_1(x9)\n",
    "        y = crop_img(x7, x)\n",
    "        x = self.up_conv_1(torch.cat([x, y], 1))\n",
    "        \n",
    "        x = self.up_trans_2(x)\n",
    "        y = crop_img(x5, x)\n",
    "        x = self.up_conv_2(torch.cat([x, y], 1))\n",
    "        \n",
    "        x = self.up_trans_3(x)\n",
    "        y = crop_img(x3, x)\n",
    "        x = self.up_conv_3(torch.cat([x, y], 1))\n",
    "        \n",
    "        x = self.up_trans_4(x)\n",
    "        y = crop_img(x1, x)\n",
    "        x = self.up_conv_4(torch.cat([x, y], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        #print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet_model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281caf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.BCEWithLogitsLoss()  # для бинарной классификации\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(UNet_model.parameters(), lr=0.001, weight_decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beecc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "history = []\n",
    "#loss_ = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    for j in range(0,200,20):\n",
    "        # Предсказание\n",
    "        y = UNet_model(data[j:j+20,:1,:572,:572])\n",
    "\n",
    "        # Вычисдение ошибки\n",
    "        loss = criterion(y, data_mask[j:j+20,:3,:388,:388])\n",
    "        history.append(loss.item())\n",
    "        #loss_ += loss\n",
    "\n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Расчет градиентов\n",
    "        loss.backward()\n",
    "\n",
    "        # Обновление градиентов\n",
    "        optimizer.step()\n",
    "        #print(loss)\n",
    "    \n",
    "    #history.append(loss_)\n",
    "    print(\"Epoches_Step: \", i + 1, \"\\t\", \"Loss_Value:\", loss.item())\n",
    "    #loss_ = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history)\n",
    "plt.title('Loss by mini_batches')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('mini_batches number')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e588f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1):    \n",
    "    y = UNet_model(data[j:j+1,:1,:572,:572])\n",
    "    img = y.detach().numpy() * 12\n",
    "    IMG = img[0].T\n",
    "\n",
    "    plt.subplots(figsize = (4,4))\n",
    "    plt.imshow(IMG)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a293a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "name_part = 'yes'        \n",
    "# Загрузка изображения\n",
    "s = 'images/brain_tumor_dataset/' + str(name_part) + '/1 (' + str(i) + ').jpg'\n",
    "img = cv.imread(s,0) \n",
    "\n",
    "#cv2.imshow('Color blue',color_image[:,:,0])\n",
    "#cv2.imshow('Color green',color_image[:,:,1])\n",
    "#cv2.imshow('Color red',color_image[:,:,2])\n",
    "\n",
    "x_new = 572\n",
    "y_new = 572\n",
    "dsize = (x_new, y_new)\n",
    "output = cv.resize(img, dsize, interpolation = cv.INTER_AREA)\n",
    "output = torch.tensor([[output.T]]).float()\n",
    "mean = output.mean()\n",
    "max_ = output.max()\n",
    "output_ = (output - mean) / max_\n",
    "plt.imshow(output_[0][0].T, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1912dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "y = UNet_model(output_[j:j+1,:1,:572,:572])\n",
    "img = y.detach().numpy() * 12\n",
    "IMG = img[0].T\n",
    "\n",
    "plt.subplots(figsize = (4,4))\n",
    "plt.imshow(IMG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in UNet_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", UNet_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4628d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fa8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "PATH = 'UNet_model.pt'\n",
    "torch.save(UNet_model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
